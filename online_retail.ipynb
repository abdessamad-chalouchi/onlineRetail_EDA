{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Project: Online Retail Exploratory Data Analysis with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this project, you will step into the shoes of an entry-level data analyst at an online retail company, helping interpret real-world data to help make a key business decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study\n",
    "In this project, you will be working with transactional data from an online retail store. The dataset contains information about customer purchases, including product details, quantities, prices, and timestamps. Your task is to explore and analyze this dataset to gain insights into the store's sales trends, customer behavior, and popular products. \n",
    "\n",
    "By conducting exploratory data analysis, you will identify patterns, outliers, and correlations in the data, allowing you to make data-driven decisions and recommendations to optimize the store's operations and improve customer satisfaction. Through visualizations and statistical analysis, you will uncover key trends, such as the busiest sales months, best-selling products, and the store's most valuable customers. Ultimately, this project aims to provide actionable insights that can drive strategic business decisions and enhance the store's overall performance in the competitive online retail market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Objectives\n",
    "1. Describe data to answer key questions to uncover insights\n",
    "2. Gain valuable insights that will help improve online retail performance\n",
    "3. Provide analytic insights and data-driven recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset you will be working with is the \"Online Retail\" dataset. It contains transactional data of an online retail store from 2010 to 2011. The dataset is available as a .xlsx file named `Online Retail.xlsx`. This data file is already included in the Coursera Jupyter Notebook environment, however if you are working off-platform it can also be downloaded [here](https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx).\n",
    "\n",
    "The dataset contains the following columns:\n",
    "\n",
    "- InvoiceNo: Invoice number of the transaction\n",
    "- StockCode: Unique code of the product\n",
    "- Description: Description of the product\n",
    "- Quantity: Quantity of the product in the transaction\n",
    "- InvoiceDate: Date and time of the transaction\n",
    "- UnitPrice: Unit price of the product\n",
    "- CustomerID: Unique identifier of the customer\n",
    "- Country: Country where the transaction occurred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "You may explore this dataset in any way you would like - however if you'd like some help getting started, here are a few ideas:\n",
    "\n",
    "1. Load the dataset into a Pandas DataFrame and display the first few rows to get an overview of the data.\n",
    "2. Perform data cleaning by handling missing values, if any, and removing any redundant or unnecessary columns.\n",
    "3. Explore the basic statistics of the dataset, including measures of central tendency and dispersion.\n",
    "4. Perform data visualization to gain insights into the dataset. Generate appropriate plots, such as histograms, scatter plots, or bar plots, to visualize different aspects of the data.\n",
    "5. Analyze the sales trends over time. Identify the busiest months and days of the week in terms of sales.\n",
    "6. Explore the top-selling products and countries based on the quantity sold.\n",
    "7. Identify any outliers or anomalies in the dataset and discuss their potential impact on the analysis.\n",
    "8. Draw conclusions and summarize your findings from the exploratory data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Importing the required libraries for EDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Loading the data into the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Online_Retail.xlsx')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Checking the types of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Dropping irrelevant columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Description', 'InvoiceNo'], axis=1)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Renaming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={\"UnitPrice\": \"Price\"})\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Dropping the duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we will show how many rows and columns we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's select all the duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_rows = data[data.duplicated()]\n",
    "print(f\"The number of duplicated rows : {duplicated_rows.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove the duplicated values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Dropping the missing or null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first let's see how many empty values we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's remove the null values from dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see that we have the exact the same number of rows in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Detecting Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['Quantity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 = data.quantile(0.25)\n",
    "# Q3 = data.quantile(0.75)\n",
    "# IQR = Q3 - Q1\n",
    "# print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Plot different features against one another (scatter), against frequency (histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the sales trends over time. Identify the busiest months and days of the week in terms of sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the busiest month in terms of sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales = data.groupby(data.InvoiceDate.dt.to_period('M'))['Quantity'].sum()\n",
    "# create a bar plot for monthly sales\n",
    "plt.figure(figsize=(15,6))\n",
    "sns.barplot(x=monthly_sales.index.to_timestamp(), y=monthly_sales)\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Monthly Sales Trend')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the busiest days in terms of sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by day of the week and sum sales\n",
    "daily_sales = data.groupby(data['InvoiceDate'].dt.dayofweek)['Quantity'].sum()\n",
    "print(daily_sales)\n",
    "# we have Saturday missing in all sales\n",
    "# Create a bar plot for daily sales\n",
    "days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Sunday']\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=days_of_week, y=daily_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the top selling product based on the quantity sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sales_by_products = data.groupby(data['StockCode'])['Quantity'].sum()\n",
    "# print(sales_by_products)\n",
    "plt.figure(figsize=(15, 6))\n",
    "# sns.barplot(x=sales_by_products['StockCode'], y=sales_by_products['Quantity'])\n",
    "sales_by_products.nlargest(40).plot(kind='bar', figsize=(10,5))\n",
    "# plt.bar(sales_by_products['StockCode'], sales_by_products['Quantity'])\n",
    "# plt.xlabel('Month')\n",
    "plt.ylabel('Total Sales')\n",
    "# plt.title('Monthly Sales Trend')\n",
    "# plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the top selling countries based on the quantity sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.head()\n",
    "sales_by_country = data.groupby(data['Country'])['Quantity'].sum()\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "sales_by_country.nlargest(40).plot(kind='bar', figsize=(10,5))\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Total Sales')\n",
    "# plt.title('Monthly Sales Trend')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our online retail business, data analysis reveals important insights. First, we cleaned the data by removing missing values and duplicates. Then, we explored the data, uncovering key trends. Notably, the UK stands out as our top-performing market. We have identified valuable insights to inform our business plan, such as monthly sales trends and profitable product categories. By focusing on the UK market and optimizing underperforming categories, we aim to enhance our business strategy continuously."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
